{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seminar 6. Feature selection & cross-validation pitfalls\n",
    "Mikhail Belyaev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Final project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Two options:\n",
    "   1. A problem related to your research or innovation activities\n",
    "   2. A real life problems selected by course instructors (a dataset from UCI or other sources);\n",
    "    \n",
    "- You can form groups up to **3** persons. \n",
    "- Please, describe the contribution of each person in the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Final projects deliverables:\n",
    " - Prepare a presentation using Jupyter notebook and submit it to Canvas\n",
    "     * Submission Deadline: Thu, 25, 12:30 Moscow time\n",
    " - Present your results to course instructors and other students (using the submitted jupyter notebook). \n",
    " - Two possible timeslots for the presentation \n",
    "     * Thu, 25\n",
    "     * Fri, 26\n",
    "     \n",
    "Monday, 22 is allocated for consultations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Actions required**\n",
    " - If you select (1), please prepare a brief description (up to 5-6 sentences) how do you want to use Machine Learning in your project.\n",
    " - If you want to form a team, please inform us (you can write a single email, but please add your teammate to the copy of your letter). \n",
    " - If you want to present your work on specific day, include this request in your letter.\n",
    "\n",
    "**Deadline** - Friday, Oct 19, 12:30 Moscow time. \n",
    "\n",
    "Please, send the required information to me (m.belyaev@skoltech.ru) **and** Maxim (m.panov@skoltech.ru). \n",
    "\n",
    "If you (or your teammate) don't send us any information, we will assign a problem to you individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seminar 5 revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt text](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png \"Bias-variance tradeoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which XGBoost parameters are the most import ones? \n",
    "\n",
    "How do these parameters affect model complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seminar 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "** 6. Features selection**\n",
    " - Effective dimensionality reduction;\n",
    " - Feature selection approaches: wrappers, filters, embedded methods;\n",
    " - Cross-validation pitfals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Selection of important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### There are three main groups of feature selection methods:\n",
    " - filters\n",
    " - wrappers\n",
    " - embedded methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "% pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Filters\n",
    "\n",
    "- estimate an importance score for each feature\n",
    "- select K most important one\n",
    "- there are a lot of different ways to calculate feature importances\n",
    "- Example: http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example 1. Good classification performance, but low statistical score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generate a simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset1():\n",
    "    X = np.random.rand(200, 2)\n",
    "    X[:100, 0] += 1\n",
    "    X[100:150, 0] += 2\n",
    "    X[100:, 1] += 0.1\n",
    "    y = np.concatenate([np.zeros(100), np.ones(100)])\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_data(X, y):\n",
    "    x_cols = ['x{}'.format(i) for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(np.hstack((X, y[:, np.newaxis])), columns=x_cols+['y'])\n",
    "    if len(x_cols) == 2:\n",
    "        sns.pairplot(df, hue='y', x_vars='x0', y_vars='x1', size=6)\n",
    "    else:\n",
    "        sns.pairplot(df, hue='y', vars=x_cols)\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# ANOVA\n",
    "selector = SelectKBest(f_classif, 1)\n",
    "selector.fit(X, y)\n",
    "# SelectKBest just selects the specified number of features with the highest scores \n",
    "print(X.shape)\n",
    "X_reduced = selector.transform(X)\n",
    "print(X_reduced.shape)\n",
    "# and what about scores?\n",
    "print(selector.scores_)\n",
    "# it selects the wrong variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# mutial information is another way to estimate scores ...\n",
    "selector = SelectKBest(mutual_info_classif, 1)\n",
    "selector.fit(X, y)\n",
    "print(selector.scores_)\n",
    "# and it works in that case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example 2. Univariate stats doesn't catch bivariate dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset2(shift=0.2):\n",
    "    X = np.random.rand(1000, 3)\n",
    "    X = X[np.abs(X[:, 1] - X[:, 0]) < 0.22]\n",
    "    X = X[np.abs(X[:, 1] - X[:, 0]) > 0.02]\n",
    "    y = X[:, 1] > X[:, 0] \n",
    "    X[y, 2] += shift\n",
    "    return X, y\n",
    "X, y = get_dataset2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(SelectKBest(f_classif, 2).fit(X, y).scores_)\n",
    "print(SelectKBest(mutual_info_classif, 2).fit(X, y).scores_)\n",
    "# both univariate methods fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Wrappers\n",
    " - a greedy alrogithm for feature adding and/or deletion\n",
    " - there are a lot of different stratigies (starting points, criteria, etc)\n",
    " - an example http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "rfe = RFE(estimator=svc, n_features_to_select=2, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rfe.fit(X, y)\n",
    "print(rfe.ranking_)\n",
    "# rank 1 means that these features were selected\n",
    "\n",
    "X_transformed = rfe.transform(X)\n",
    "plt.plot(X[:, 0], X[:, 1], '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embedded \n",
    "- features are selected automatically as a part of the learning process \n",
    "- an example - linear models with the L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt text](https://1.bp.blogspot.com/-tXq6Nl2lcNg/V3qzttiZ4sI/AAAAAAAAN_M/6nmjgwydWJUy5Kqt9gFg2Nb12BCTcD4ogCLcB/s1600/LASSO.png  \"Embedded feature selection methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty='l1', C=0.09)\n",
    "clf.fit(X, y)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "L1-penalty based approaches are a cool class of methods, but in case of correlated variables it can drop relevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let us make the last component fully irrelevant and try a L1-based method again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = get_dataset2(shift=0)\n",
    "df = pd.DataFrame(np.hstack((X, y[:, np.newaxis])), columns=['x0', 'x1', 'x2', 'y'])\n",
    "sns.pairplot(df, hue='y', vars=['x0', 'x1', 'x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l1', C=0.2)\n",
    "clf.fit(X, y)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature selection: a small example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### TODO: \n",
    " - load an anonimized dataset from dataset3.csv\n",
    " - estimate the 10 most important features (using f_classif)\n",
    " - perform cross-validation & estimate classification quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_dataset3():\n",
    "    # insert your code here\n",
    "    return X, y\n",
    "X, y = get_dataset3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# it's an anonimized dataset with standatized features\n",
    "print('Data shape is {}'.format(X.shape))\n",
    "print('Class 0 size is {}'.format(sum(y==0)))\n",
    "print('Class 1 size is {}'.format(sum(y==1)))\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The number of features is too large, so it seems to be a good idea to start with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# TODO fit SelectKBest and select 10 best features\n",
    "# selector = ...\n",
    "\n",
    "# SelectKBest just selects the specified number of features with the highest scores \n",
    "\n",
    "# print(X.shape)\n",
    "# X_reduced = selector.transform(X)\n",
    "# print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Now we have a reasonable number of features and can estimate classification accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# TODO apply logistic regression to the reduced data set and estimate accuracy using cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: what if we skip the feature selection step?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### So, we've obtained a great result using feature selection! Probably, too good to be true ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sanity check: randomly shuffle labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_random = y.copy() \n",
    "np.random.shuffle(y_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: estimate accuracy of the pipeline\n",
    "# as we shuffle the labels, we need to fit the selector again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### There is a mistake somewhere ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### We used *all* available data for feature selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to do a multistep analysis in a correct way? Use pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(SelectKBest(f_classif, 10), \n",
    "                      LogisticRegression())\n",
    "scores = cross_val_score(pipe, X, y_random, scoring='accuracy', cv=5)\n",
    "print('Accuracy of classification is {:0.2f} +- {:0.2f}'.format(np.mean(scores), np.std(scores)))\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, scoring='accuracy', cv=5)\n",
    "print('Accuracy of classification is {:0.2f} +- {:0.2f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Feature importances: ensembles of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ensembles of trees are usually based on a large set of features, and it's hardly possible to represent such complex models by simple equations. However, there are two other meaningful properties of predictive models which can be used to interpret results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The first useful property is an ability to automatically find important combinations of features and then visualize model predictions as a function of these combinations. The boosted trees models don't allow to create such figures, and the only opportunity is to plot pairwise interactions of the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Another desired property of predictive models is an ability to estimate the importance of each feature. Unfortunately, boosted trees as well as other tree-based ensemble methods tend to overestimate importance of actually unimportant features if dataset contains highly correlated features, see: \n",
    " *Auret, L. & Aldrich, C. Empirical comparison of tree ensemble variable importance mea-sures. Chemometrics and Intelligent Laboratory Systems105,157–170 (2011)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A sklearn example of embedded feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "X, y = make_classification(n_samples=1000,\n",
    "                           n_features=10,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=0,\n",
    "                           n_repeated=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=0,\n",
    "                           shuffle=False)\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### TODO: add some correlated features and check the result (keyword n_redundant of make_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#template to estimate XGB importance\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X, y)\n",
    "importances = clf.feature_importances_\n",
    "plt.hist(importances);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Another possible pitfall: selection of hyperparameters & grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def f_poly(x, coefs):\n",
    "    summands = [x**(power+1) * coef for power, coef in enumerate(coefs)]\n",
    "    return np.array(summands).sum(0)\n",
    "\n",
    "def get_function(coefs=None):\n",
    "    if coefs is None:\n",
    "        coefs = [1, -0.5, -1, 0.6]\n",
    "    return lambda x: f_poly(x, coefs)\n",
    "\n",
    "def get_dataset4(f, sample_size, noise_std=0.1):\n",
    "    X = np.random.rand(sample_size, 1) * 2 - 1\n",
    "    y = f(X)\n",
    "    y += np.random.randn(*y.shape) * noise_std\n",
    "    return X, y\n",
    "\n",
    "def plot_dataset4(f, X=None, y=None, regr=None):\n",
    "    X_plot = np.linspace(-1, 1, 100)[:, np.newaxis]\n",
    "    plt.plot(X_plot, f(X_plot), label='True function')\n",
    "    if X is not None and y is not None:\n",
    "        plt.plot(X, y, '.r')\n",
    "    if regr is not None:\n",
    "        plt.plot(X_plot, regr.predict(X_plot), label='Prediction')\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim([-0.8, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Lets generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f = get_function()\n",
    "X, y = get_dataset4(f, 20)\n",
    "X_test, y_test = get_dataset4(f, 100)\n",
    "plot_dataset4(f, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### We'll use a polinomial model to fit the data and ridge regression to estimate coefficients of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "regr = make_pipeline(PolynomialFeatures(20), Ridge())\n",
    "regr.fit(X, y)\n",
    "plot_dataset4(f, X, y, regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.regression import mean_squared_error as mse\n",
    "\n",
    "def get_errors(regr, X, y):\n",
    "    y_predicted = regr.predict(X)\n",
    "    mse(y, y_predicted)**0.5\n",
    "    return mse(y, y_predicted)**0.5\n",
    "print('Root mean squared error is {}'.format(get_errors(regr, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt text](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png \"Bias-variance tradeoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### We can use regularization to control model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = get_dataset4(f, 20)\n",
    "regr = make_pipeline(PolynomialFeatures(20), Ridge(1e-9))\n",
    "regr.fit(X, y)\n",
    "print('Root mean squared error is {}'.format(get_errors(regr, X_test, y_test)))\n",
    "plot_dataset4(f, X, y, regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = get_dataset4(f, 20)\n",
    "regr = make_pipeline(PolynomialFeatures(20), Ridge(1e9))\n",
    "regr.fit(X, y)\n",
    "print('Root mean squared error is {}'.format(get_errors(regr, X_test, y_test)))\n",
    "plot_dataset4(f, X, y, regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = get_dataset4(f, 20)\n",
    "regr = make_pipeline(PolynomialFeatures(20), Ridge(0.1))\n",
    "regr.fit(X, y)\n",
    "print('Root mean squared error is {}'.format(get_errors(regr, X_test, y_test)))\n",
    "plot_dataset4(f, X, y, regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### So, quality depends on regularization parameter significantly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to select model parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# our model is a pipeline, so we have to use a special format to specify parameters\n",
    "# \n",
    "parameters = {'ridge__alpha':10**np.linspace(-5, 5, 21)}\n",
    "regr = make_pipeline(PolynomialFeatures(20), Ridge())\n",
    "regr_grid = GridSearchCV(regr, parameters)\n",
    "regr_grid.fit(X, y)\n",
    "\n",
    "plot_dataset4(f, X, y, regr_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But what is we have more than one parameter to adjust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "parameters = {'learning_rate': [0.001, 0.005, 0.01, 0.025, 0.05, 0.1],\n",
    "              'max_depth': range(1, 10),\n",
    "              'n_estimators': [5, 10, 20, 35, 50, 100],\n",
    "             }\n",
    "clf_grid = GridSearchCV(clf, parameters, n_jobs=-1, verbose=True)\n",
    "X, y = get_dataset3()\n",
    "clf_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "best_score_ = clf_grid.best_score_\n",
    "print(best_score_)\n",
    "best_params = clf_grid.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An error with a fixed parameters is a random variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: execute this cell multiple times and track function's behavior and the error\n",
    "X, y = get_dataset4(f, 20)\n",
    "regr = make_pipeline(PolynomialFeatures(20), Ridge(1e-4))\n",
    "regr.fit(X, y)\n",
    "print('Root mean squared error is {}'.format(get_errors(regr, X_test, y_test)))\n",
    "plot_dataset4(f, X, y, regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### We can plot distribution of erros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### for a single model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores(regr, sample_size, n_repeats):\n",
    "    scores = []\n",
    "    for i in range(n_repeats):\n",
    "        X, y = get_dataset4(f, sample_size)\n",
    "        regr.fit(X, y)\n",
    "        scores.append(get_errors(regr, X_test, y_test))\n",
    "    return scores\n",
    "regr = make_pipeline(PolynomialFeatures(20), Ridge())\n",
    "scores = get_scores(regr, sample_size=20, n_repeats=100)\n",
    "sns.distplot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### ... and for several model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "sns.despine(left=True)\n",
    "\n",
    "def plot_hist(alpha, color, ax):\n",
    "    regr = make_pipeline(PolynomialFeatures(20), Ridge(alpha=alpha))\n",
    "    scores = get_scores(regr, 20, n_repeats=100)\n",
    "    sns.distplot(scores, color=color, ax=ax)\n",
    "    ax.set_title('Regularization is {}'.format(alpha))\n",
    "\n",
    "plot_hist(alpha=1e-9, color='r', ax=axes[0, 0])\n",
    "plot_hist(alpha=1e-4, color='g', ax=axes[0, 1])\n",
    "plot_hist(alpha=1e-1, color='b', ax=axes[1, 0])\n",
    "plot_hist(alpha=1e9, color='m', ax=axes[1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now check the optimal parameters which were found by GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "scores = []\n",
    "X, y = get_dataset3()\n",
    "for i in range(100):\n",
    "    clf = GradientBoostingClassifier(**best_params)\n",
    "    cv = KFold(random_state=i, shuffle=True)\n",
    "    score = cross_val_score(clf, X, y, cv=cv, n_jobs=-1).mean()\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(scores)\n",
    "# sns.distplot([best_score_]*100)\n",
    "plt.plot([best_score_] * 10 , range(10), 'r', label='the score from grid-search')\n",
    "plt.plot([np.median(scores)] * 10 , range(10), 'g', label='median score')\n",
    "plt.plot([np.mean(y==0)] * 10 , range(10), 'k', label='naive \"always says zero\" score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### The grid-search score is better than the highest possible accuracy level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The problem is that GridSearchCV gives you a single number from the whole distribution. Due to a greedy nature of the algorithm, this score is usually too optimistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Take-away messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " - Ideally, use an independent test set \n",
    " - If you use multistep anysis always chain these steps into a single sklearn pipeline\n",
    " - As a sanity check, you can feed to your analysis random variables and compare the obrained results with the expected quality of random classification\n",
    " - Do not trust GridSearchCV results, always re-check the optimal comination of parameters"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
